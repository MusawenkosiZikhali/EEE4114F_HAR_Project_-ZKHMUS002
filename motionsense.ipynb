{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6536a38c",
   "metadata": {},
   "source": [
    "# Human Activity Recognition\n",
    "This notebook provides some guidelines for building a classifier for the MotionSense dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05398592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49379c42",
   "metadata": {},
   "source": [
    "# Generate time-series data\n",
    "The original MotionSense dataset comes in a slightly cumbersome format, but the authors do provide a few functions to produce Pandas DataFrames with control over what is produced. For our purposes we are not concerned with all of the target data, as we only need to know the activity that was being recorded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4fa97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_infos():\n",
    "    \"\"\"\n",
    "    Read the file includes data subject information.\n",
    "\n",
    "    EEE4114: Technically we do not need these data, as we are not concerned about identifying the subjects. \n",
    "    \n",
    "    Data Columns:\n",
    "    0: code [1-24]\n",
    "    1: weight [kg]\n",
    "    2: height [cm]\n",
    "    3: age [years]\n",
    "    4: gender [0:Female, 1:Male]\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame that contains information about data subjects' attributes \n",
    "    \"\"\" \n",
    "\n",
    "    dss = pd.read_csv(\"data_subjects_info.csv\")\n",
    "    print(\"[INFO] -- Data subjects' information is imported.\")\n",
    "    \n",
    "    return dss\n",
    "\n",
    "def set_data_types(data_types=[\"userAcceleration\"]):\n",
    "    \"\"\"\n",
    "    Select the sensors and the mode to shape the final dataset. \n",
    "\n",
    "    EEE4114F: Choose sensors that you think are useful or would like to include in training. \n",
    "    You can choose all of them, or you could opt to try a limited set of input features\n",
    "    \n",
    "    Args:\n",
    "        data_types: A list of sensor data type from this list: [attitude, gravity, rotationRate, userAcceleration] \n",
    "\n",
    "    Returns:\n",
    "        It returns a list of columns to use for creating time-series from files.\n",
    "    \"\"\"\n",
    "    dt_list = []\n",
    "    for t in data_types:\n",
    "        if t != \"attitude\":\n",
    "            dt_list.append([t+\".x\",t+\".y\",t+\".z\"])\n",
    "        else:\n",
    "            dt_list.append([t+\".roll\", t+\".pitch\", t+\".yaw\"])\n",
    "\n",
    "    return dt_list\n",
    "\n",
    "\n",
    "def create_time_series(dt_list, act_labels, trial_codes, mode=\"mag\", labeled=True):\n",
    "    \"\"\"\n",
    "    EEE4114F: This defines what data you would like to include for a given set.  \n",
    "\n",
    "    Args:\n",
    "        dt_list: A list of columns that shows the type of data we want.\n",
    "        act_labels: list of activites\n",
    "        trial_codes: list of trials\n",
    "        mode: It can be \"raw\" which means you want raw data\n",
    "        for every dimension of each data type,\n",
    "        [attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)].\n",
    "        or it can be \"mag\" which means you only want the magnitude for each data type: (x^2+y^2+z^2)^(1/2)\n",
    "        labeled: True, if we want a labeled dataset. False, if we only want sensor values.\n",
    "\n",
    "    Returns:\n",
    "        It returns a time-series of sensor data.\n",
    "    \n",
    "    \"\"\"\n",
    "    num_data_cols = len(dt_list) if mode == \"mag\" else len(dt_list*3)\n",
    "\n",
    "    if labeled:\n",
    "        dataset = np.zeros((0,num_data_cols+1)) # \"1\" --> [act] we do not need the other labels\n",
    "    else:\n",
    "        dataset = np.zeros((0,num_data_cols))\n",
    "        \n",
    "    ds_list = get_ds_infos()\n",
    "    \n",
    "    print(\"[INFO] -- Creating Time-Series\")\n",
    "    for sub_id in ds_list[\"code\"]:\n",
    "        for act_id, act in enumerate(act_labels):\n",
    "            for trial in trial_codes[act_id]:\n",
    "                fname = 'A_DeviceMotion_data/'+act+'_'+str(trial)+'/sub_'+str(int(sub_id))+'.csv'\n",
    "                raw_data = pd.read_csv(fname)\n",
    "                raw_data = raw_data.drop(['Unnamed: 0'], axis=1)\n",
    "                vals = np.zeros((len(raw_data), num_data_cols))\n",
    "                for x_id, axes in enumerate(dt_list):\n",
    "                    if mode == \"mag\":\n",
    "                        vals[:,x_id] = (raw_data[axes]**2).sum(axis=1)**0.5        \n",
    "                    else:\n",
    "                        vals[:,x_id*3:(x_id+1)*3] = raw_data[axes].values\n",
    "                    vals = vals[:,:num_data_cols]\n",
    "                if labeled:\n",
    "                    lbls = np.array([[act_id]]*len(raw_data))\n",
    "                    vals = np.concatenate((vals, lbls), axis=1)\n",
    "                dataset = np.append(dataset,vals, axis=0)\n",
    "    cols = []\n",
    "    for axes in dt_list:\n",
    "        if mode == \"raw\":\n",
    "            cols += axes\n",
    "        else:\n",
    "            cols += [str(axes[0][:-2])]\n",
    "            \n",
    "    if labeled:\n",
    "        cols += [\"act\"]\n",
    "    \n",
    "    dataset = pd.DataFrame(data=dataset, columns=cols)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffdb25b",
   "metadata": {},
   "source": [
    "You would need to decide what to include in your dataset, for example if you want to try a reduce dataset with only a few sensors then you can alter the `sdt` list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce4af905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Selected sensor data types: ['attitude', 'userAcceleration']\n",
      "[INFO] -- Selected activities: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset: (767660, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude.roll</th>\n",
       "      <th>attitude.pitch</th>\n",
       "      <th>attitude.yaw</th>\n",
       "      <th>userAcceleration.x</th>\n",
       "      <th>userAcceleration.y</th>\n",
       "      <th>userAcceleration.z</th>\n",
       "      <th>act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.528132</td>\n",
       "      <td>-0.733896</td>\n",
       "      <td>0.696372</td>\n",
       "      <td>0.294894</td>\n",
       "      <td>-0.184493</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.527992</td>\n",
       "      <td>-0.716987</td>\n",
       "      <td>0.677762</td>\n",
       "      <td>0.219405</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.114866</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.527765</td>\n",
       "      <td>-0.706999</td>\n",
       "      <td>0.670951</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.516768</td>\n",
       "      <td>-0.704678</td>\n",
       "      <td>0.675735</td>\n",
       "      <td>-0.008389</td>\n",
       "      <td>0.136788</td>\n",
       "      <td>0.094958</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493941</td>\n",
       "      <td>-0.703918</td>\n",
       "      <td>0.672994</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.353996</td>\n",
       "      <td>-0.044299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude.roll  attitude.pitch  attitude.yaw  userAcceleration.x  \\\n",
       "0       1.528132       -0.733896      0.696372            0.294894   \n",
       "1       1.527992       -0.716987      0.677762            0.219405   \n",
       "2       1.527765       -0.706999      0.670951            0.010714   \n",
       "3       1.516768       -0.704678      0.675735           -0.008389   \n",
       "4       1.493941       -0.703918      0.672994            0.199441   \n",
       "\n",
       "   userAcceleration.y  userAcceleration.z  act  \n",
       "0           -0.184493            0.377542  0.0  \n",
       "1            0.035846            0.114866  0.0  \n",
       "2            0.134701           -0.167808  0.0  \n",
       "3            0.136788            0.094958  0.0  \n",
       "4            0.353996           -0.044299  0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define activities and trials (unchanged)\n",
    "ACT_LABELS = [\"dws\", \"ups\", \"wlk\", \"jog\", \"std\", \"sit\"]\n",
    "TRIAL_CODES = {\n",
    "    ACT_LABELS[0]: [1, 2, 11],\n",
    "    ACT_LABELS[1]: [3, 4, 12],\n",
    "    ACT_LABELS[2]: [7, 8, 15],\n",
    "    ACT_LABELS[3]: [9, 16],\n",
    "    ACT_LABELS[4]: [6, 14],\n",
    "    ACT_LABELS[5]: [5, 13]\n",
    "    \n",
    "}\n",
    "\n",
    "# Set parameters for the reduced dataset\n",
    "sdt = [\"attitude\",\"userAcceleration\"]  # Reduced to only userAcceleration\n",
    "print(\"[INFO] -- Selected sensor data types: \" + str(sdt))\n",
    "act_labels = ACT_LABELS[0:4]  # Keep dws, ups, wlk, jog\n",
    "print(\"[INFO] -- Selected activities: \" + str(act_labels))\n",
    "trial_codes = [TRIAL_CODES[act] for act in act_labels]  # Trials for selected activities\n",
    "dt_list = set_data_types(sdt)  # Generates [\"userAcceleration.x\", \"userAcceleration.y\", \"userAcceleration.z\"]\n",
    "dataset = create_time_series(dt_list, act_labels, trial_codes, mode=\"raw\", labeled=True)\n",
    "print(\"[INFO] -- Shape of time-Series dataset: \" + str(dataset.shape))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51fcfc85",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'act'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'act'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Separate labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m labels \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m features \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns in dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataset\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5819\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   5778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5780\u001b[0m \u001b[38;5;124;03m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[0;32m   5781\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5817\u001b[0m \u001b[38;5;124;03m    3  monkey        NaN\u001b[39;00m\n\u001b[0;32m   5818\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpop(item\u001b[38;5;241m=\u001b[39mitem)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:947\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m Any:\n\u001b[1;32m--> 947\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[item]\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m[item]\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'act'"
     ]
    }
   ],
   "source": [
    "# Separate labels\n",
    "labels = dataset.pop(\"act\").astype(int).values\n",
    "features = dataset.values\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# --- Create time windows for CNN input ---\n",
    "def create_sequences(X, y, window_size=100, step=50):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_size, step):\n",
    "        Xs.append(X[i:i+window_size])\n",
    "        ys.append(y[i+window_size-1])  # Use label at the end of window\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(features, labels, window_size=100, step=50)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_seq, y_seq, test_size=0.1, stratify=y_seq, random_state=42\n",
    ")\n",
    "\n",
    "# Optional: map activity IDs to names for later\n",
    "activity_map = {i: act_labels[i] for i in range(len(act_labels))}\n",
    "print(\"[INFO] CNN input shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0a9c25",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "There are numerous approaches to solving this task and your choice of algorithm will determine what form your input data should take. For example, a feed-forward neural network could be used, but what type of representation would make sense? Without being able to account for the temporal structure of the data, feed-forward networks might fail. One way around this is to potentially use summarized statistics about the data to simplify the features in a way that is not reliant on temporal information. E.g. instead of the raw signal for the acceleration, what if you worked with the mean? This might not be the best approach, compared to other algorithms, but it could be useful for a feed-forward network.\n",
    "\n",
    "what about convolutional neural networks? Well, you could use 1D convolutions directly on time-series data which would then result in fewer model parameters compared to a fully-connected network, with the added benefit of retaining temporal information. Alternatively you could look to transform the time-series data into 2D data using something such as an FFT to produce a spectogram. Or for something simpler you can create fixed windows to divide your dataset into chunks of 2D data e.g. for 6 sensors and a window of 400 samples you would generate a 6 x 400 input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c80505",
   "metadata": {},
   "source": [
    "# Pytorch Dataset\n",
    "If using Pytorch it is useful to create datasets using their dataset structures. This may require modification if using additional transformations, or formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80b0ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotionSense(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        # X should be (num_windows, n_sensors, window_size)\n",
    "        # Permute to (num_windows, window_size, n_sensors) for storage, then adjust in __getitem__\n",
    "        self.X = torch.FloatTensor(X.transpose((0, 2, 1)))  # Shape: (num_windows, window_size, n_sensors)\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.item()\n",
    "        x = self.X[index]  # Shape: (window_size, n_sensors)\n",
    "        # Permute to (n_sensors, window_size) for Conv1d\n",
    "        x = x.transpose(0, 1)  # Shape: (n_sensors, window_size)\n",
    "        y = self.y[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9503b",
   "metadata": {},
   "source": [
    "# Resampling\n",
    "You can split the dataset using sklearn, but you need to take care with your specific data. For example, randomly splitting raw sensor data will result in jumbled time-series signals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e102709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = dataset[[col for col in dataset.columns if col != \"act\"]]  # Collect input data\n",
    "#y = dataset[\"act\"]  # Collect target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63575a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may be tempted to use train_test_split directly. But if using raw sensor data this would randomize the signals and not retain the order. \n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "026c2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4421d5c",
   "metadata": {},
   "source": [
    "Notice the indeces are all jumbled? If using windowed data the usual splitting methods work, as each window retains the order of sensor values, as long as you split the data along the correct axis. \n",
    "\n",
    "If using summarized data e.g. taking the mean, max, min etc. as input features rather than the raw data then you should be fine using train_test_split.\n",
    "\n",
    "If working with raw sensor data there is an sklearn fuction for splitting time series data to make splitting raw signals easier if you want to work with that instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d51bd192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of the TimeSeriesSplit. It does create cross-validation data by default. \n",
    "#ts_cv = TimeSeriesSplit(\n",
    "#    n_splits=5,\n",
    "#    gap=20,\n",
    "#    max_train_size=10000,\n",
    "#    test_size=1000\n",
    "#)\n",
    "\n",
    "#all_splits = list(ts_cv.split(X ,y)) # These are indices, not the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce931631",
   "metadata": {},
   "source": [
    "Once you have the indices you can sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bd05035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.iloc[all_splits[0][0]].head() # This is the training input data from the first split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8eff6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.iloc[all_splits[0][0]].head() # This is the training target data from the first split. You can see the indices still match, and arre ordered correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68be307",
   "metadata": {},
   "source": [
    "Once you have your splits, you can convert them to Pytorch datasets for easier loading. Technically you could offload the sampling methods to Pytorch samplers, but this can be trickier to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3440c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_1 = MotionSense(X.iloc[all_splits[0][0]].reset_index(drop=True).values, \n",
    "#                      y.iloc[all_splits[0][0]].reset_index(drop=True).values) # reset_index is to make sure each new set is indexed from 0\n",
    "#train_1_loader = DataLoader(train_1, batch_size=32)  # Will load data in batches. Batching raw signals can be problematic if it cuts-off a given signal, or stitches it together with other signals etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991d427",
   "metadata": {},
   "source": [
    "# Models\n",
    "As mentioned previously there are a few options for the types of models you end up using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54ccb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualHAR_CNN(nn.Module):\n",
    "    def __init__(self, input_dim, n_classes, window_size):\n",
    "        super(DualHAR_CNN, self).__init__()\n",
    "\n",
    "        # Branch 1\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        # Branch 2\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 32, kernel_size=5, padding=2),  # different kernel\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        # Output shape after conv/pooling: (128 + 64) × (window_size // 4)\n",
    "        combined_channels = (128 + 64) * (window_size // 4)\n",
    "        \n",
    "        self.fc1 = nn.Linear(combined_channels, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # shape: (B, D, T)\n",
    "\n",
    "        out1 = self.branch1(x)  # shape: (B, 128, T//4)\n",
    "        out2 = self.branch2(x)  # shape: (B, 64, T//4)\n",
    "\n",
    "        # Concatenate features from both branches\n",
    "        combined = torch.cat((out1, out2), dim=1)  # (B, 192, T//4)\n",
    "        combined = combined.view(combined.size(0), -1)  # flatten\n",
    "\n",
    "        out = self.dropout(self.fc1(combined))\n",
    "        return self.fc2(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee2480d",
   "metadata": {},
   "source": [
    "# Training\n",
    "With your model defined you will need to decide on an optimizer used to perform parameter updates. The choice is yours, but for the most part default optimizers like Adam should work for CNNs, although SGD can be more stable but take longer to train. \n",
    "\n",
    "You can then load in data, for example if using the loader described before the loop shown below will iterate through batches of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b27dc84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 0.5874\n",
      "[Epoch 2] Loss: 0.2812\n",
      "[Epoch 3] Loss: 0.1891\n",
      "[Epoch 4] Loss: 0.1325\n",
      "[Epoch 5] Loss: 0.1128\n",
      "[Epoch 6] Loss: 0.0951\n",
      "[Epoch 7] Loss: 0.0681\n",
      "[Epoch 8] Loss: 0.0686\n",
      "[Epoch 9] Loss: 0.0475\n",
      "[Epoch 10] Loss: 0.0333\n",
      "[Epoch 11] Loss: 0.0365\n",
      "[Epoch 12] Loss: 0.0365\n",
      "[Epoch 13] Loss: 0.0446\n",
      "[Epoch 14] Loss: 0.0332\n",
      "[Epoch 15] Loss: 0.0251\n",
      "[Epoch 16] Loss: 0.0305\n",
      "[Epoch 17] Loss: 0.0208\n",
      "[Epoch 18] Loss: 0.0196\n",
      "[Epoch 19] Loss: 0.0215\n",
      "[Epoch 20] Loss: 0.0168\n",
      "[Epoch 21] Loss: 0.0298\n",
      "[Epoch 22] Loss: 0.0219\n",
      "[Epoch 23] Loss: 0.0188\n",
      "[Epoch 24] Loss: 0.0211\n",
      "[Epoch 25] Loss: 0.0231\n",
      "[Epoch 26] Loss: 0.0137\n",
      "[Epoch 27] Loss: 0.0120\n",
      "[Epoch 28] Loss: 0.0066\n",
      "[Epoch 29] Loss: 0.0095\n",
      "[Epoch 30] Loss: 0.0375\n",
      "[Epoch 31] Loss: 0.0176\n",
      "[Epoch 32] Loss: 0.0089\n",
      "[Epoch 33] Loss: 0.0147\n",
      "[Epoch 34] Loss: 0.0107\n",
      "[Epoch 35] Loss: 0.0277\n",
      "[Epoch 36] Loss: 0.0298\n",
      "[Epoch 37] Loss: 0.0144\n",
      "[Epoch 38] Loss: 0.0095\n",
      "[Epoch 39] Loss: 0.0181\n",
      "[Epoch 40] Loss: 0.0055\n",
      "[Epoch 41] Loss: 0.0081\n",
      "[Epoch 42] Loss: 0.0176\n",
      "[Epoch 43] Loss: 0.0137\n",
      "[Epoch 44] Loss: 0.0235\n",
      "[Epoch 45] Loss: 0.0210\n",
      "[Epoch 46] Loss: 0.0096\n",
      "[Epoch 47] Loss: 0.0096\n",
      "[Epoch 48] Loss: 0.0099\n",
      "[Epoch 49] Loss: 0.0078\n",
      "[Epoch 50] Loss: 0.0166\n"
     ]
    }
   ],
   "source": [
    "# Assuming DualHAR_CNN is defined already (from earlier)\n",
    "\n",
    "# Set parameters\n",
    "n_classes = len(np.unique(y_train))\n",
    "input_dim = X_train.shape[2]\n",
    "window_size = X_train.shape[1]\n",
    "\n",
    "# ✅ Instantiate the model\n",
    "model = DualHAR_CNN(input_dim=input_dim, n_classes=n_classes, window_size=window_size)\n",
    "\n",
    "# ✅ Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "                             # ✅ Convert your data into PyTorch tensors and DataLoader\n",
    "train_data = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.long)\n",
    ")\n",
    "\n",
    "test_data = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.long)\n",
    ")\n",
    "\n",
    "# ✅ Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0aa1b",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Make sure to correctly evaluate your models. Justify your methods given your particular model and data used e.g. if you use random holdout, is it justified? What do your performance metrics tell you e.g. was the model overfitting, underfitting, are their early stages in the training process where the model performs well compared to the end of training, which model do you choose to save, are the model outputs \"reasonable\" i.e. are there errors that might make sense given the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "772ea085-900c-4e4d-a54d-74bf706a4944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Testing Accuracy: 95.83%\n",
      "\n",
      "[INFO] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.97      0.90      0.93       263\n",
      "         ups       0.92      0.96      0.94       315\n",
      "         wlk       0.97      0.98      0.98       689\n",
      "         jog       0.96      0.97      0.96       269\n",
      "\n",
      "    accuracy                           0.96      1536\n",
      "   macro avg       0.95      0.95      0.95      1536\n",
      "weighted avg       0.96      0.96      0.96      1536\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Inference (no gradients)\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "# Compute accuracy\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"[INFO] Testing Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n[INFO] Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=act_labels))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=act_labels, yticklabels=act_labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"CNN Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
